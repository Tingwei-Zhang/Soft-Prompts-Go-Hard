# Scripts Directory

This directory contains scripts for running experiments with different vision-language models (VLMs) on various datasets. The scripts are organized by model type and dataset.

## Directory Structure

```
script/
├── blip/
│   ├── blip_imagenet_script/
│   └── blip_coco_script/
├── llava/
│   ├── llava_example.sh
│   ├── llava_imagenet_script/
│   └── llava_coco_script/
└── minigpt4/
    ├── minigpt4_imagenet_script/
    └── minigpt4_coco_script/
```

## Script Types

### Attack Scripts
- Scripts for generating image soft prompts through visual attacks
- Key parameters:
  - `--n_iters`: Number of optimization iterations (default: 2000)
  - `--constrained`: Attack constraint type ('constrained' or 'partial' or 'l2')
  - `--eps`: Maximum perturbation magnitude (e.g., 16, 32)
  - `--alpha`: Step size for gradient updates
  - `--image_file`: Path to the input image
  - `--save_dir`: Directory to save adversarial examples
  - `instruction`: Target meta-objective for the attack

### Inference Scripts  
- Scripts for evaluating model performance on soft prompts
- Key parameters:
  - `--data_path`: Path to the instruction dataset
  - `--image_file`: Path to the adversarial image
  - `--output_file`: Path to save inference results
  - `instruction`: Meta-objective used for evaluating explicit prompt and image content alignment

## Example Usage

### LLaVA Example (Sentiment - Positive)
```bash
# Running a visual attack for positive sentiment
python llava_llama_v2_visual_attack.py \
    --data_path instruction_data/eg4/dataset.csv \
    --instruction positive \
    --n_iters 2000 \
    --constrained constrained \
    --eps 128 \
    --alpha 1 \
    --image_file clean_images/eg1.png \
    --save_dir output/llava/eg1/Sentiment/Positive/partial_eps_128_batch_8
```

### MiniGPT-4 Example (Sentiment - Positive)
```bash
# Running a visual attack for positive sentiment
python minigpt4_visual_attack.py \
    --data_path instruction_data/eg4/dataset.csv \
    --instruction positive \
    --n_iters 2000 \
    --constrained constrained \
    --eps 32 \
    --alpha 1 \
    --image_file clean_images/eg1.png \
    --save_dir output/minigpt4/eg1/Sentiment/Positive/partial_eps_128_batch_8
```

### BLIP Example (Sentiment - Positive)
```bash
# Running a visual attack for positive sentiment
python blip_visual_attack.py \
    --data_path instruction_data/eg4/dataset.csv \
    --instruction positive \
    --n_iters 2000 \
    --constrained constrained \
    --eps 32 \
    --alpha 1 \
    --image_file clean_images/eg4.png \
    --save_dir output/blip/eg4/Sentiment/Positive/partial_eps_128_batch_8
```

## Other Usage

### Baseline Evaluations

- **Baseline 1 (No Attack):**
  Run inference on the clean image with the default prompt.
  ```bash
  python -u [model]_inference.py --data_path ... --image_file clean_images/[id].png --output_file output/[model]/[id]/baseline_1/result.jsonl
  ```
- **Baseline 2 (Explicit Instruction):**
  Run inference on the clean image with an explicit instruction (meta-objective) provided.
  ```bash
  python -u [model]_inference.py --data_path ... --image_file clean_images/[id].png --output_file output/[model]/[id]/[Task]/[Instruction]/baseline_2/result.jsonl --instruction [instruction]
  ```
- **Our Method (Adversarial Image):**
  Run inference on the adversarial image generated by the attack script.
  ```bash
  python -u [model]_inference.py --data_path ... --image_file output/[model]/[id]/[Task]/[Instruction]/[constraint]/bad_prompt.bmp --output_file output/[model]/[id]/[Task]/[Instruction]/[constraint]/result.jsonl
  ```

---

### Content Evaluation (LDI)

- **Purpose:**
  To check if the model's output matches the label/content of the image (binary classification: does the label describe the image?).
- **How to Run:**
  For both clean and adversarial images, use the following command:
  ```bash
  python -u [model]_inference.py --image_file [image_path] --image_index [index] --output_file [output_path] --instruction inference_content_evaluation
  ```
  - For clean images, use `clean_images/[id].png`.
  - For adversarial images, use `output/[model]/[id]/[Task]/[Instruction]/[constraint]/bad_prompt.bmp`.

---

### L2 and Transferability Experiments

- **L2 Attack:**
  Some scripts use `--constrained l2` and different `--eps` values (e.g., 6, 12, 24).
  Example:
  ```bash
  python minigpt_visual_attack.py --constrained l2 --eps 24 ...
  ```
  See scripts like `script_sentiment_minigpt4_l2_24.sh` for batch runs.

- **Transferability:**
  To test if adversarial images generated for one model transfer to another, use the transfer scripts (e.g., `transfer_minigpt4.sh`).
  Example:
  ```bash
  python -u minigpt_inference.py --data_path ... --image_file output/llava/[id]/[Task]/[Instruction]/[constraint]/bad_prompt.bmp --output_file output/minigpt4/[id]/[Task]/[Instruction]/[constraint]/transfer_result.jsonl
  ```

---

### Batch Experiments

- Each subdirectory (e.g., `blip_coco_script/`, `llava_imagenet_script.sh/`) contains shell scripts for running all experiments for a given task or dataset.
- To run all experiments for a task, simply execute the corresponding shell script:
  ```bash
  bash script/blip/blip_coco_script/script_sentiment_blip.sh
  ```

---

## Output Directory Structure

- `[model_name]`: The model used (e.g., `llava`, `minigpt4`, `blip`)
- `[experiment_name]`: The image or dataset identifier (e.g., `coco_1`)
- `[task_type]`: The meta-objective/task (e.g., `Positive`, `Negative`)
- `[constraint_type]_eps_[value]_batch_[size]`: Attack constraint and parameters
- Files:
  - `bad_prompt.bmp`: The adversarial image
  - `result.jsonl`: Inference results
  - `content_classification_result.jsonl`: Content evaluation results

